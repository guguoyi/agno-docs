---
title: Agent with Output Model
description: "Use a secondary model to format the final response."
---

Use `output_model` to delegate final response generation to a different model. The primary model handles research, reasoning, and tool calls, then the output model formats the final response.

Common use cases:
- **Cost optimization**: Use a powerful model for complex tasks, a cheaper model for formatting
- **Specialized output**: Use models optimized for different tasks (e.g., research vs. writing)
- **Cross-provider**: Combine models from different providers

## Code

```python output_model.py
from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.tools.hackernews import HackerNewsTools

agent = Agent(
    model=OpenAIResponses(id="gpt-5.2"),
    output_model=OpenAIResponses(id="gpt-5.2"),
    output_model_prompt="Format the research findings as a concise executive summary with bullet points.",
    tools=[HackerNewsTools()],
)

agent.print_response("What are the top AI stories on HackerNews?", stream=True)
```

The primary model (`gpt-5.2`) researches HackerNews using tools, then the output model (`gpt-4o`) formats the findings according to the prompt.

## Usage

<Steps>

  <Snippet file="create-venv-step.mdx" />

  <Step title="Install dependencies">
    ```bash
    uv pip install -U agno openai
    ```
  </Step>

  <Step title="Export your OpenAI API key">

    <CodeGroup>

    ```bash Mac/Linux
    export OPENAI_API_KEY="your_openai_api_key_here"
    ```

    ```bash Windows
    $Env:OPENAI_API_KEY="your_openai_api_key_here"
    ```
    </CodeGroup>
  </Step>

  <Step title="Run Agent">
    ```bash
    python output_model.py
    ```
  </Step>

</Steps>
