---
title: Output Model
sidebarTitle: Output Model
description: Use a secondary model to format the final response.
---

Use `output_model` to delegate final response formatting to a different model. The primary model handles reasoning and tool calls, then the output model formats the result.

## Why Use an Output Model?

| Use Case | Example |
|----------|---------|
| Better writing | Research with GPT-5.2, write with Claude Opus 4.5 |
| Cost optimization | Reason with DeepSeek, format with GPT-5-mini |
| Structured output | Use a model without native support, format with one that has it |

## Better Writing

GPT-5.2 excels at research and tool use, but Claude Opus 4.5 produces better prose. Combine them:
```python
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.models.openai import OpenAIResponses
from agno.tools.hackernews import HackerNewsTools

agent = Agent(
    model=OpenAIResponses(id="gpt-5.2"),       # Research and tool calls
    output_model=Claude(id="claude-opus-4-5"), # Creative writing
    output_model_prompt="Write an engaging, well-structured article based on these findings.",
    tools=[HackerNewsTools()],
)

agent.print_response("Write an article about the latest AI breakthroughs", stream=True)
```

The primary model gathers information from HackerNews. Claude Opus 4.5 transforms those findings into polished prose.

## Cost Optimization

Use a capable but expensive model for complex reasoning, a cheaper model for formatting:
```python
from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=OpenAIResponses(id="gpt-5.2"),       # Expensive: complex analysis + tools
    output_model=OpenAIResponses(id="gpt-5-mini"),  # Cheap: just formatting
    output_model_prompt="Summarize the analysis in 3 bullet points.",
    tools=[YFinanceTools()],
)

agent.print_response("Deep analysis of NVDA financials", stream=True)
```

Or use a cheaper reasoning model with a better formatting model:
```python
from agno.agent import Agent
from agno.models.deepseek import DeepSeek
from agno.models.openai import OpenAIResponses
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=DeepSeek(id="deepseek-chat"),        # Cheap: reasoning + tools
    output_model=OpenAIResponses(id="gpt-5.2"), # Better formatting
    tools=[YFinanceTools()],
)

agent.print_response("Analyze AAPL stock performance", stream=True)
```

## Structured Output Support

Some models lack native structured output. Use an output model that supports it:
```python
from pydantic import BaseModel, Field
from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.tools.hackernews import HackerNewsTools

class ArticleSummary(BaseModel):
    title: str
    key_points: list[str] = Field(description="3-5 main takeaways")
    sentiment: str = Field(description="positive, negative, or neutral")

agent = Agent(
    model=OpenAIResponses(id="gpt-5.2"),            # Primary reasoning
    output_model=OpenAIResponses(id="gpt-5.2"),    # Structured output
    output_schema=ArticleSummary,
    tools=[HackerNewsTools()],
)

response = agent.run("Summarize the top AI story on HackerNews")
summary: ArticleSummary = response.content
print(summary.key_points)
```

## How It Works

1. Primary model processes the request and executes tool calls
2. Primary model generates an intermediate response
3. Intermediate response passes to the output model
4. Output model formats and returns the final response

## Custom Formatting Prompt

Use `output_model_prompt` to control the output style:
```python
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.models.openai import OpenAIResponses
from agno.tools.hackernews import HackerNewsTools

# Executive summary style
agent = Agent(
    model=OpenAIResponses(id="gpt-5.2"),
    output_model=Claude(id="claude-sonnet-4-5"),
    output_model_prompt="Format as a concise executive summary. No fluff, just insights.",
    tools=[HackerNewsTools()],
)

# Technical documentation style
agent = Agent(
    model=OpenAIResponses(id="gpt-5.2"),
    output_model=Claude(id="claude-sonnet-4-5"),
    output_model_prompt="Format as technical documentation with code examples where relevant.",
    tools=[HackerNewsTools()],
)
```

## When to Use Output Model

| Scenario | Recommendation |
|----------|----------------|
| Need better prose quality | `output_model` with Claude Opus 4.5 |
| Need to reduce costs | `output_model` with GPT-5-mini |
| Primary model lacks structured output | `output_model` + `output_schema` |
| Need specific formatting style | `output_model` + `output_model_prompt` |
| Simple structured data extraction | `output_schema` alone (no output model needed) |

## Related

- [Structured Output](/basics/input-output/structured-output/agent): Get validated Pydantic objects
- [Structured Input](/basics/input-output/structured-input/agent): Pass validated input to agents