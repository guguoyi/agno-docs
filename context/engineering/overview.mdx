---
title: Context Engineering
sidebarTitle: Overview
description: Design and control the information sent to language models to guide their behavior.
keywords: [context, context engineering, system message, user message, prompts, prompt engineering]
---

Context engineering is the process of designing and controlling the information (context) that is sent to language models to guide their behavior and outputs. 
In practice, building context comes down to one question: "Which information is most likely to achieve the desired outcome?"

In Agno, this means carefully crafting the system message, which includes the agent or team description, instructions, and other relevant settings. By thoughtfully constructing this context, you can:

- Steer your agent or team toward specific behaviors or roles.
- Constrain or expand your agent or team's capabilities.
- Ensure outputs are consistent, relevant, and aligned with your application's needs.
- Enable advanced use cases such as multi-step reasoning, tool use, or structured output.

Effective context engineering is an iterative process: refining the system message, trying out different descriptions and instructions, and using features such as schemas, delegation, and tool integrations.

The context of an Agno agent consists of the following:
- **System message**: The system message is the main context that is sent to the agent or team, including all additional context
- **User message**: The user message is the message that is sent to the agent or team.
- **Chat history**: The chat history is the history of the conversation between the agent or team and the user.
- **Additional input**: Any few-shot examples or other additional input that is added to the context.


## Context Caching

Most model providers support caching of system and user messages, though the implementation differs between providers.

The general approach is to cache repetitive content and common instructions, and then reuse that cached content in subsequent requests as the prefix of your system message.
In other words, if the model supports it, you can reduce the number of tokens sent to the model by putting static content at the start of your system message.

Agno's context construction is designed to place the most likely static content at the beginning of the system message.  
If you wish to fine-tune this, the recommended approach is to manually set the system message.

Some examples of prompt caching:
- [OpenAI's prompt caching](https://platform.openai.com/docs/guides/prompt-caching)
- [Anthropic prompt caching](https://docs.claude.com/en/docs/build-with-claude/prompt-caching) -> See an [Agno example](/integrations/models/native/anthropic/usage/prompt-caching) of this
- [OpenRouter prompt caching](https://openrouter.ai/docs/features/prompt-caching)


## Learn more
<CardGroup cols={3}>
  <Card
    title="Context Engineering for Agents"
    icon="robot"
    iconType="duotone"
    href="/context/engineering/agent/overview"
  >
    Craft system messages and instructions for agents.
  </Card>
  <Card
    title="Context Engineering for Teams"
    icon="users"
    iconType="duotone"
    href="/context/engineering/team/overview"
  >
    Configure context for multi-agent coordination.
  </Card>
  <Card
    title="Chat History"
    icon="history"
    iconType="duotone"
    href="/context/history/overview"
  >
    Include conversation history in context.
  </Card>
</CardGroup>