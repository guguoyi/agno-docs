---
title: CSV Row Chunking
---

CSV row chunking is a method of splitting CSV files into smaller chunks based on the number of rows, rather than character count. This approach is particularly useful for structured data where you want to process CSV files in manageable row-based chunks while preserving the integrity of individual records.

<Steps>

  <Step title="Create a Python file">
    ```python csv_row_chunking.py
    import asyncio
    from agno.agent import Agent
    from agno.knowledge.chunking.row import RowChunking
    from agno.knowledge.knowledge import Knowledge
    from agno.knowledge.reader.csv_reader import CSVReader
    from agno.vectordb.pgvector import PgVector

    db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

    knowledge_base = Knowledge(
        vector_db=PgVector(table_name="imdb_movies_row_chunking", db_url=db_url),
    )

    asyncio.run(knowledge_base.ainsert(
        url="https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
        reader=CSVReader(
            chunking_strategy=RowChunking(),
        ),
    ))

    # Initialize the Agent with the knowledge_base
    agent = Agent(
        knowledge=knowledge_base,
        search_knowledge=True,
    )

    # Use the agent
    agent.print_response("Tell me about the movie Guardians of the Galaxy", markdown=True)
    ```
  </Step>

  <Snippet file="create-venv-step.mdx" />

  <Step title="Install dependencies">
    ```bash
    uv pip install -U agno sqlalchemy psycopg pgvector
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run the script">
    ```bash
    python csv_row_chunking.py
    ```
  </Step>

</Steps>

## CSV Row Chunking Params

<Snippet file="chunking-csv-row.mdx" /> 
