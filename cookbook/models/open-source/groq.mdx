---
title: Groq
description: Use Llama, Mixtral, and DeepSeek models with ultra-fast inference.
---

Groq provides the fastest inference for open-source models. Sub-second responses for Llama and Mixtral.

```python
from agno.agent import Agent
from agno.models.groq import Groq

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    markdown=True,
)

agent.print_response("Explain quantum computing", stream=True)
```

## Tool Use

```python
from agno.agent import Agent
from agno.models.groq import Groq
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    tools=[YFinanceTools(stock_price=True)],
    markdown=True,
)

agent.print_response("What's NVDA's stock price?", stream=True)
```

## Reasoning (DeepSeek-R1)

```python
from agno.agent import Agent
from agno.models.groq import Groq

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    reasoning_model=Groq(
        id="deepseek-r1-distill-llama-70b",
        temperature=0.6,
        max_tokens=1024,
    ),
)

agent.print_response("Is 9.11 bigger or 9.9?", stream=True)
```

## Structured Output

```python
from pydantic import BaseModel, Field
from agno.agent import Agent
from agno.models.groq import Groq

class Summary(BaseModel):
    title: str = Field(..., description="Article title")
    key_points: list[str] = Field(..., description="Key points")
    sentiment: str = Field(..., description="Overall sentiment")

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    output_schema=Summary,
)

agent.print_response("Summarize the benefits of open-source AI")
```

## Run Examples

```bash
export GROQ_API_KEY=xxx

git clone https://github.com/agno-agi/agno.git
cd agno/cookbook/92_models/groq

python basic.py
python tool_use.py
python reasoning_agent.py
```
