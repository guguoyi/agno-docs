---
title: Model Examples
sidebarTitle: Overview
description: 700+ examples across 40+ LLM providers. Same Agent code, use any model.
---

Agno's model abstraction lets you switch providers with one line of code. Every example works with the same Agent interface.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.models.anthropic import Claude
from agno.models.google import Gemini

# Same agent code, different models
agent = Agent(model=OpenAIResponses(id="gpt-5.2"))
agent = Agent(model=Claude(id="claude-sonnet-4-5"))
agent = Agent(model=Gemini(id="gemini-3-flash-preview"))
```

## Provider Categories

<CardGroup cols={3}>
  <Card title="OpenAI" icon="microchip" href="/cookbook/models/openai">
    GPT models with tools, vision, audio, and reasoning.
  </Card>
  <Card title="Anthropic" icon="brain" href="/cookbook/models/anthropic">
    Sonnet and Opus with extended thinking and prompt caching.
  </Card>
  <Card title="Google" icon="google" href="/cookbook/models/google">
    Gemini with native video, audio, search, and Imagen generation.
  </Card>
  <Card title="Open Source" icon="code-branch" href="/cookbook/models/open-source">
    Llama, Mistral, DeepSeek via Groq, Together, Fireworks.
  </Card>
  <Card title="Enterprise" icon="building" href="/cookbook/models/enterprise">
    Azure OpenAI, AWS Bedrock, Vertex AI, NVIDIA, IBM watsonx.
  </Card>
  <Card title="Local" icon="server" href="/cookbook/models/local">
    Ollama, vLLM, LMStudio for private, offline inference.
  </Card>
</CardGroup>

## All Providers

| Provider | Import |
|----------|--------|
| OpenAI | `from agno.models.openai import OpenAIResponses` |
| Anthropic | `from agno.models.anthropic import Claude` |
| Google | `from agno.models.google import Gemini` |
| xAI | `from agno.models.xai import xAI` |
| Perplexity | `from agno.models.perplexity import Perplexity` |
| Groq | `from agno.models.groq import Groq` |
| DeepSeek | `from agno.models.deepseek import DeepSeek` |
| Mistral | `from agno.models.mistral import MistralChat` |
| Together | `from agno.models.together import Together` |
| Fireworks | `from agno.models.fireworks import Fireworks` |
| Cohere | `from agno.models.cohere import CohereChat` |
| Cerebras | `from agno.models.cerebras import Cerebras` |
| Azure OpenAI | `from agno.models.azure import AzureOpenAI` |
| Azure AI Foundry | `from agno.models.azure import AzureAIFoundry` |
| AWS Bedrock | `from agno.models.aws import BedrockChat` |
| Vertex AI | `from agno.models.vertexai import VertexAI` |
| NVIDIA | `from agno.models.nvidia import NVIDIAChat` |
| IBM watsonx | `from agno.models.ibm import WatsonX` |
| Ollama | `from agno.models.ollama import Ollama` |
| vLLM | `from agno.models.vllm import vLLM` |
| LMStudio | `from agno.models.lmstudio import LMStudio` |
| llama.cpp | `from agno.models.llamacpp import LlamaCpp` |
| LiteLLM | `from agno.models.litellm import LiteLLM` |
| OpenRouter | `from agno.models.openrouter import OpenRouter` |
| Portkey | `from agno.models.portkey import Portkey` |

## Quick Start

```python
from agno.agent import Agent
from agno.models.anthropic import Claude

agent = Agent(
    model=Claude(id="claude-sonnet-4-5"),
    instructions=["Be concise"],
    markdown=True,
)

agent.print_response("What is quantum computing?", stream=True)
```

## Run Examples

```bash
git clone https://github.com/agno-agi/agno.git
cd agno/cookbook/90_models

# Set API key for your provider
export OPENAI_API_KEY=xxx
export ANTHROPIC_API_KEY=xxx
export GOOGLE_API_KEY=xxx

# Run examples
python openai/responses/basic.py
python anthropic/basic.py
python google/gemini/basic.py
```

View all examples in the [cookbook on GitHub](https://github.com/agno-agi/agno/tree/main/cookbook/90_models).
