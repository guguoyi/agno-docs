---
title: Perplexity
sidebarTitle: Overview
description: Use Perplexity models with built-in web search in Agno agents.
---

Perplexity offers powerful language models with built-in web search capabilities, enabling advanced research and Q&A functionality.

Explore Perplexityâ€™s models [here](https://docs.perplexity.ai/guides/model-cards).

## Authentication

Set your `PERPLEXITY_API_KEY` environment variable. Get your key [from Perplexity here](https://www.perplexity.ai/settings/api).

<CodeGroup>

```bash Mac
export PERPLEXITY_API_KEY=***
```

```bash Windows
setx PERPLEXITY_API_KEY ***
```

</CodeGroup>

## Example

Use `Perplexity` with your `Agent`:

<CodeGroup>

```python agent.py
from agno.agent import Agent
from agno.models.perplexity import Perplexity

agent = Agent(model=Perplexity(id="sonar-pro"), markdown=True)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

```

</CodeGroup>

<Note> View more examples [here](/integrations/models/native/perplexity/usage/basic). </Note>

## Params

| Parameter    | Type               | Default                        | Description                                                           |
| ------------ | ------------------ | ------------------------------ | --------------------------------------------------------------------- |
| `id`         | `str`              | `"sonar"`                     | The ID of the Perplexity model to use                          |
| `name`       | `str`              | `"Perplexity"`                | The name of the model                                                 |
| `provider`   | `str`              | `"Perplexity"`                | The provider of the model                                             |
| `api_key`    | `Optional[str]`    | `None`                         | The API key for Perplexity (defaults to PERPLEXITY_API_KEY env var)  |
| `base_url`   | `str`              | `"https://api.perplexity.ai/"` | The base URL for the Perplexity API                                   |
| `max_tokens` | `int`              | `1024`                         | Maximum number of tokens to generate                                  |
| `top_k`      | `Optional[float]`  | `None`                         | Number of highest probability tokens to consider for generation       |
| `collect_metrics_on_completion` | `bool` | `True`              | Collect token metrics only from the final streaming chunk (for providers with cumulative token counts) |

`Perplexity` also supports the params of [OpenAI](/reference/models/openai).
